04/30/14
First basic implementation of an automaton. Question: which alphabet? We will here consider the integers. NO UPPER BOUND hypothesis must be made!
Mu and Rho are (hash)maps.
There seems to be a link with CNF and SAT solving problem; take a look later.
For now, the transition set is seen as sparse: a matrix representation is therefore useless. We also maximise reading access times: the transition system is seen as a hashset (key: state) of a hashset (key: label) of a list of states.
Each automaton object is seen as an automaton model; the object is immutable during any computation.
First write deterministic algorithm.
New question: how does one perform a quick check of whether there is a register that contains the current symbol? For now, we'll do it naïvely: check all the registers. Later on, an optimisation is to keep a record of the current registers' content in form of a (hash)set.
This algorithm is/could be linear with the number of symbols to test. The number of registers and states does not impact the computation time.

Questions:
“A Turing machine can simulate membership for NFA in NLOG”: how?
Computational complexity of MEMD.
Why use reduction while it's straightforward?

See email dated today: ignore these questions, authors made some unclear assertions.

05/01/14
[coding nondeterministic membership]
Try:
A basic BFS/other search algorithm. An interesting heuristic should be found.
A different vision over the problem:

A RA can be seen as an NFA over a finite word w over a finite alphabet E: w is composed of the register indices where symbols are progressively stored (or not); in the end a word is exactly a string of transition labels, as shown in the representation of a RA.

[reflexion on emptiness]
If there is a word in the language defined by an automaton A, then the following algorithm will return such a word:
BFS/A* search from initial state to final state. Not to be confused with the search STATE.
If the language is empty, this search will not terminate, which makes the algorithm/the method useless.

FMA (Kaminski) has some mistakes, i.e. p 334 tau values do not have to be distinct (“abaaba” passes membership test).

05/02/14
Finished nondeterministic membership problem with a first naïve solution: just LDFTS. A next step would be to find a nice heuristic.

Could it be possible to divide an automaton into two subsets, deterministic states and nondeterministic ones, and then see the problem as a “chance” game? Or a game with contingency plans? MINIMAX?

05/03/14
Empirical emptiness problem: PROPOSITION: it is only necessary to test the automaton with the following subset of the alphabet:
{elements in the initial registers} U {other distinct elements}
the total set size being the number of registers + 1.

WHY: we always need the possibility of filling up all the registers and having new elements coming in, which is why there need to be at least NR+1 elements in the alphabet subset.
The automaton can only remember seeing NR elements, so if there is always a new element, it will be seen as “new”.

05/04/14
The first version of a naïve empirical emptiness check works. It probably does way too much work: when all words of size N are refused, words of size N+1 are checked, and the work done on size N is forgotten and recomputed (very intensive).
In each case it works perfectly, and for example for Example 3 (automaton recognising words with double repetition, ie two different symbols are repeated): [1,1,0,0] is returned.

Idea: create a “generative” emptiness check, with the previous intuition; the decision algorithm would actually be complete given the previous PROPOSITION: the state space is big but not infinite.
The decision algorithm would be based on a BFGS/A*G algorithm, where the G factor is very important: we are not interested in cycles. We can see the problem as a search problem from an initial state to whatever final state we reach first. A* could use a heuristic based on the physical distance of the state to a final state (to be precomputed).
WARNING: there might be unvoluntary cycles introduced if we go to the same state, with the same registers assigned, but with different values. Since all assigned values are distinct, there might be some symmetry (isomorphism) in this CSP that could be avoided.

05/05/14
Generative emptiness seems to work OK. Some mistakes have been made regarding permutations of register values (see previous WARNING).

-> Meeting with supervisor; TODO:
- Deterministic membership is straightforward, agreed.
- Nondeterministic membership can be optimised by using an adapted version of BFTS: Breadth-First-Local-Graph-Search. LDFTS performs less good in a diamond-chain-shaped automaton's case: BFLGS will be linear in all cases, LDFTS will be exponential as usual. Try to find an example where LDFTS performs better; idea: choose a tree that has a lot of branches with a deep-found solution. This only works better if the word is part of the language.
- Nondeterministic can also be solved by assigning hashmaps to each physical state, where a value (label?) points towards a set of configurations. To be explored and implemented.
- Emptiness decision problem: the equality check should be reviewed as explained above.
- Read the paper about emptiness, the proof is probably very similar to what's going on in the chosen algorithm.
- Also try out a heuristic for emptiness checking (A*). This might speed up cases where the language is nonempty.
- Explore language inclusion
- All the previous algorithms should be tested on useful examples of automata. Random generation can be inspired from random graph generation. Then a good idea is to start with a small sticky manual example, and try to generalise it and automatise its generation. The diamond-chain-shaped automata are a good example of what kind of automaton can be automatically generated.

Example 4 is a basic example where LDFTS is disastrous in case the word is not in the language.

It seems that BFLGS is indeed useful in the case of a diamond-chain-shaped automaton, but how useful is it in average? And compared to LDFTS?
STRATEGY: 
1) Get tests up and running: 
	a. Find interesting automata for testing
	b. Improve the results container to get more interesting results:
		- Number of nodes expanded
		- Frontier size
		- Operations performed
2) Implement different algorithms for nondeterministic membership
3) Compare on large automata

So there we go:
1) Random automata seem OK, but we have to find out how to choose the parameters that go with them. Quick cleanup of RAGenerator's structure.

Finished Diamond-chain-shaped (DCS) automata.

05/06/14
Now improving test infrastructure.

05/08/14
Test infrastructure has been improved a lot. Some work still needs to be done (polymorphism of algorithms and search algorithms for instance).
Diamond-chain-shaped automata seem to give the expected result: DFS is explosive (exponential increase) while SB-BFS is linear. Tests made with listed membership test infrastructure.

Some questions:
- How useful would it be to test all the algorithms?
- Why is the DCS automaton's instance interesting?
- Try to find a nice example where BFLGS loses all its efficiency.

* The point is that DFS can be -asymptotically- worse than SB-BFS (see example 4).

SB-BFS can be worse than DFS but not asymptotically. 
Proof:

We're going to show that SB-BFS has, in the worst case, always the same asymptotic performance as DFS. The case where membership fails is straightforward: DFS and SB-BFS expand all the nodes, and because of pruning, SB-BFS does always better. We're looking for a case where DFS decides faster, and that's only possible if membership succeeds.

Reformulation:
Let A be an automaton, with registers R and state set Q. Let (wn) be an infinite word list such that DFS finds a path in O(f(n)) nodes expanded for wn in A, and |wn| = n (i.e. the path is of length n). We suppose that, on this list, SB-BFS is worse in the number of nodes expanded. Let's show that SB-BFS's performance is in O(f(n)).

Let S be a frontier at some point in SB-BFS's exploration. The search states in this frontier are distinguished by three criteria:
- The sublist of letters in the word left to explore
- The values in the registers
- The name of the current physical state

As it happens:
- A frontier in BFS symbolises a circle in a state space where the distance is the number of nodes in the path to go from one space to the other; in other words, for every search state in S, the sublist of letters to explore is the same.
- Let A be the set of letters in the initial word, and |A| its size. Then there are D = (|A|+1)^|R| possibilities of register assignments.
- There are |Q| possible physical states.
As a consequence, the maximum number of search states in S is D*|Q|.

SB-BFS finds the solution in n frontier swaps. Therefore it must expand in the worst case D*|Q|*n nodes. But:
- DFS has a better performance in this example. Let g(n) be the number of nodes DFS expands in search for the final state. Then g(n) <= D*|Q|*n.
- DFS must at least expand n nodes. Therefore

		n <= g(n) <= D*|Q|*n

and two results are inferred:
- g(m) = O(m) (i.e. a candidate for f is n → n)
- since D*|Q|*m = O(m), SB-BFS has the same asymptotic performance as DFS.

Therefore, in case DFS has a better performance than SB-BFS, even then SB-BFS does not have a worse asymptotic performance.

A case where SB-BFS is worse than DFS: example5.fma. See test21.csv. This example is a fork between example 4 and another useless cyclic automaton. BFS's frontier will always be bigger, and therefore in DFS's optimal case, DFS is faster. Furthermore, there is just a factor 3 difference.

DFS is always worse than SB-BFS when membership fails.

05/10/14

What happens if DFS had a priority-set? Direct consequence: its frontier cannot have repetitions.

This would have no consequence at all: almost every node in DFS's frontier respects the following rules:
- either the nodes have a unique word-to-explore length left
- or, if that's not the case, they are different physical states.
This would only be useful in case several identical transitions go from the same node to the same node.

The idea to implement states with hashsets seems already used: for the moment, a configuration can input a label to output a configuration. Ask again for what the idea was.

The membership problem with heuristics: A* to solve membership. Interesting when there are many choices of paths; A* would use a priority-set. But which heuristic?
→ [[Physical distance from goals]]: constraint relaxation on the label of the transitions. Two problems arise:
	* There are often several final states; this implies several distances, while a heuristic is real-valued
	* Cycles introduce more different distances, and with this distances can be in infinite numbers

IDEA: pre-process the automaton and attribute a score map to each physical state, ie for state s a function f_s such that:
	f_s : n → f_s(n),
where n is the number of letters left to process in the word, and f_s(n) is the number of physical paths that exist from that node to a final node.

What is the value of f_f(0) where state f is final? -1 could be used for unset, -2 for final states, 0 for states with no path to a final state, and >0 for regular values.

Note that this could lead to a lighter version of the automaton, with all terminal non-final states removed...

f_s is difficult to find. The best way would be to have a real function making a computation using + and * operations, based on cycles detection. Is that possible? If not we'll have to find alternatives:
	* A first solution consists in computing f_s(n) naïvely on the spot. A* expands a node, a few new configurations arrive, what is their f_s score? This results in a basic graph search for a path of determined length to final nodes (BFS: count all the final nodes at the bottom of the full search tree). This is very computationnally expensive and doesn't seem to add any performance.
	* A second solution could be to compute f_s(n) on the spot, but by using peer f_s values: let q1 and q2 be two adjacent states, and suppose m transitions exist from q1 to q2. Then:
	f_q1_q2(n) = m * f_q2(n-1) if f_q2(n-1) > 0 else 0
and f_q1 = sum(f_q1_q, q adjacent to q1).


(NB: suppose adjacent node s has p paths to final state. If we have one transition to s, that means still p paths. If we have two transitions, that means 2p paths, because for each path we can choose either the first or the second transition twice the number of possibilities).)

Each time an f_s is computed, its value is stored in an array (and not a hashset!) contained within the physical set, and can then be reused later. If adjacent values exist, this method is not too expensive. It is however impractical if, say, the aim is to test only one word of length 1,000, 10,000, …
	* A third solution is to compute f_s for all states s for all lengths n < N before actually starting any membership tests. This is a linear operation in N. Then the automaton could be pruned from useless states as pointed out above.

All in all these methods will take a lot of memory (one million states with one million-length words is one terabyte of necessary memory and is not computable; ten thousand states with word length a thousand is 10 million bytes (10M) which is still acceptable), and the initial computation process (if present) might take some time.

In the code repository, f will named “hscore”.

→ A heuristic based on labels. Could make some kind of density in the label “1”, which could advise on a certain direction to take...

05/12/14
Meeting with supervisor.
------------------------

- Previous proof was OK but it's possible to find better asymptotically for DFS if the automaton varies as well. The idea is an automaton with n branches for the initial state, and it's actually a tree of depth n with all leaf states final: DFS finds the solution in n, and BFS in 3^n for example.

- MORE on paper

Implementing heuristic: physical distance.

The Hscore value can be computed faster if all terminal states (without outgoing transitions) have their values set to 0 and are then ignored. 

Practical question: would it be better to have a set instead of a list in the transition hashmap? A list allows to reach the same state twice or more from the same state with the same label, which is useless...

Think about a speedup algorithm: reduce automata. Remove terminal states, double transitions, and think about more.

It seems that the Hscore idea has a problem: the numbers are too large. Think about it: a one-state double recursion implies 2^1000 paths for a 1000-letter long word. It is impossible to store this number. However, we might want to store the saturated value just for the principle of making the point: “here are a lot of possibilities!”.

Small optimisation: PrioritySet will not accept states with score 0.

Test infrastructure needs to be improved further to make decision algorithms additions easier.

05/13/14
Question: is there a way, given the minimal alphabet subset, to transform an FMA into an NFA?

Implemented better test infrastructure, algorithms are now objects.

Debugging Best-First search.

05/14/14
Best-First search works.

In which case(s) does it work better than BFLGS? For the handwritten examples, it expands less nodes, but is more costly time-wise.

It obviously works better as the automaton's search tree grows “wider”; try to find an example for this.

Suppose the automaton is a tree with several branches from the root but then only 1-width paths to final states. In that case Best-First search will entirely behave like BFLGS: the heuristic will push it to explore all the root's branches step by step. DFS would remain -asymptotically- better.

→ Best-First search has to be improved! There must be a proximity factor included. 

This proximity factor is easy to find: we know the distance from our goal. A suggestion for including this proximity factor is a lexicographical comparison in form of (distance, number of paths > 0).

This implies modifying the frontier and create an A*ish version of best-first. Done.

Let's now implement a new generator that, given n, generates a tree with n root signle branches terminated by final states.

Most of the examples only have one or two registers; especially for the ones with one register, this kind of defeats the purpose of register automata: where's the difference with NFA?

Best-First is dangerous because elements are placed randomly in the queue if they have the same heuristic. The frontier at that point is no longer a queue nor a stack. Rather than forcing this behaviour it seems more legitimate to actually abaondon the concept.

05/16/14
Reading, and trying to answer the following question: do FMAs include NFAs, or vice-versa, or not at all?

FMAs include NFAs in a quite obvious manner (initialise registers of size of finite alphabet and deactivate all rhos).
05/18/14
For emptiness, there is an easy heuristic to apply as well: physical distance from any target. [TODO]

Register content checking is very slow: linear check in the number of registers. Optimisation to get rid of this linear factor: instead of storing (regNumber → regSymbol), we store (regSymbol → regNumber, or <0 if not assigned). This has the same memory consumption if the alphabet is encoded intelligently (R elements and therefore a very small array).

05/19/14
Meeting with Radu:
- HEURISTICS
Need proof that it actually works well. Targetted word size, if automaton size doesn't change, is around a million.
Try to find a workaround for the integer limit problem by using logarithms (which conserve order).
- INCLUSION
Read the paper about the inclusion proof: with more than two registers “the problem is undecidable”.
Test inclusion up to a certain length by generating paths similarly to emptiness, and by testing membership. Test on both example automata.
- JAVA TRACES
Useful to test properties. Things to do:
* Implement an RA for the hasNext property
* Collect data and (filter) translate into a word that is understandable by the automaton
* Test with different algorithms.
* Implement more properties (Collections, HttpResponse)

Also two papers to read about related subjects: Paths through graphs, and testing algorithms.

Will start by gathering test data from Java programs.

05/20/14
Succeeded in creating a JDI implementation to monitor a program's acitvity. Now possible to translate into intelligent integers, for property checking.

05/21/14
1. Write translator
2. Write automaton example
3. Extend test infrastructure for 1 word only
4. Test with different program examples

Tests made on single-iterator example: single-iterator.tr

All done. In case membership fails, even for the has-next property, LDFTS is unable to terminate in time. A* has terrible performance as well; the only one more or less reasonable is BFLGS.

05/22/14
In case of membership failure (which is what we are trying to prove), it's normal A* fails miserably: it will have the same behaviour as LDFTS.

Trying with more complex example programs for HNP: Multiple Random Iterator Generation results in ultra large traces, and these take ages to process.

A less naïve version of the translation (only relevant events) allow to 

Weirdly enough, the number of expanded nodes increases linearly, and the time squarely.

05/26/14
Email Runtime Verification owner: to get properties. [DONE]
DaCapo: traces from other projects, run with custom debugger.
More properties.
Paper: API usage patterns + Radu's paper
Translation including garbage collection preprocessing: grabage state.
Use profiler to accelerate

Bloom Filters: fast membership checking in a set.

Sets in registers
SAT subsuming.

---

No need for word comparison when computing hashcodes for BFLGS: for each state in a frontier, all word-to-explore lengths are the same.

Action plan:
------------
1. Go over BFLGS for some low-level optimisations and run the same tests again for comparison. Use profiler if necessary.
2.a Look at return values for traces; modify the hasNext property test.
2.b Implement garbage collection given this: extend the automaton.
2. Implement the properties on Wikipedia and test them.
3. Ask for Radu's paper.
4.a Look at assigning hash maps to each state in order not to compute “expand”.
4.b Explore new ways of automaton exploration: Bloom filters? belief states? sets in registers? Can be useful for emptiness.
5. Look at Runtime Verification papers: can their techniques be used with RA? How do logic languages behave regarding RA?

05/27/14
Idea to be explored later: set-based BFS puts word-to-explore lengths on the same level. What if a search algorithm did the same but with the configuration's “current state” or the configuration's “register contents” (up to isomorphism)? To be tried out...

Go for action plan:
1. Going through BFLGS for optimisations.
Will clone search state and search node code for direct optimisations.

Stripped BFLGS (now opti BFLGS) from redundant hashcode checking: performance is skyrocketting! Will acquire more test data because currently insufficient.

Maximum test data length is now 30,000 symbols. Now 50,000! But the JVM seems to be doing plenty of stuff during the tests, therefore killing the performance for some words.

VisualVM says the most used methods are “decide” and “expand”, which is not a surprise. Trying to optimise now...

To be tested: replace the array list by a linked list for the left-over word. Try generating all the search states and choose from them, rather than creating new objects each time. Try collapsing search states and nodes.

Tried right away: change decision function type from “int[]” to “list<int>” where the implementation of the list is not important.

Analysing the performance increase pooling could have on this memory issue: Garbage Collection seems to happen at the wrong moment, killing measures. How to circumvent this by reusing objects? 

05/28/14
Article below claims this has no use, which makes sense. Maybe the question is rather, how to benchmark with Java?

THE ERROR: two-fold:
- by remembering the path of node parents, all nodes are kept! (Inform Peter Jeavons)
- by making sublists of sublists, all the sublists are kept in memory, the whole tree!

Taking out the sublists is a 10% gain on time.
Taking out paths allows to handle 100,000 symbols in under 10s, probably because GC issues are no longer.

05/29/14
Tiny optimisation: when considering checking a property, to know whether a search state is final, no need to check the word size: if it is possible to reach a final state with the current trace, the property check fails!

2.a Replaced all entry events by exit events, in order to have their return value has well.

Adapting translator to incorporate return values from hasNext: done. Now rewriting automaton.

05/30/14
There is a performance loss because of the paradigm: “Any symbol should either be present or stored”. The model should be extended with the possibility to ignore the next symbol. But this is really a tiny optimisation.

2.a Automaton rewritten, it works.

2.b Unable to find where “finalize” is supposed to come in... Iterators seem to be destroyed without this method being called.

06/01/14
Reading paper, “A Theoretician's Guide to the Experimental Analysis of Algorithms” by David S. Johnson.

Some random notes: 
* Need to explore the optimisation of replacing linear read search by double memory usage (sparse array) for registers.
* Useful to explore compatibility with multi-core? OpenCL?
* Need to get rid of variability in algorithm tests. In particular, GC's behaviour should be predicted.
* Implement runtime verification properties, and reimplement solutions that were already given. THEN compare to newly found algorithms/register automata's case.
* Optimise algorithms as much as possible: do not “claim not enough programming was done” and let the reader figure it out for themselves.
* Our measure of performance will be the number of nodes expanded (time spent in bottleneck) and frontier size (number of nodes in memory). This is reproducible because machine-independent.
* Use benchmark program to benchmark processor speed once the report will be written.
* Format results numbers in an intelligent way (not too much digits) and explain doing so.
* Display graphs by manipulating data: rescale axes, such as by applying a log scale or something else: the nice result is the one with a line instead of a curve.

How to transform LTL in a register automaton? Nice introduction for final report here. Should be fairly easy. It's a way to say runtime verification properties are easily implementable in this manner.

– Now reading “Garbage Collection for Monitoring Parametric Properties”, by D. Jin et al. 

The introduction starts with saying runtime verification of parametric properties is made by slicing the trace and checking each parameter with a different monitor. This is of course very satisfactory here: we don't have to take into account parameters.
It is unsure Register Automata will yield better performance: there has to be some ID checking which infers more intermediary operations. However, we will have to take into account the “slicing” phase.
There is a lot of BS about the genericity of the system the authors have created, but it does not seem relevant: that's engineering, not research.

Also another incentive to implement abstract garbage collection. Garbage collection is in our case much easier because it simply includes the 

BFS is good because we know its runtime in advance.

It seems it will be hard comparing figures with this paper, because this is an online analysis (aka of “overhead” problems). With what could this algorithm be compared?

06/02/14
For future properties to be tested, sometimes more than one type of object is employed (Collection and Iterator, ...), which is not currently a possibility. Add a custom translation module?

Compare with JavaMOP.

06/04/14
Comparison drastically failed: JavaMOP is basically a black box, and it will be difficult to use it.

A new automaton generator is being created, to recognise the Advanced Finite Memory statements language (AMA). This will ease up the process of creating property-recognising automata (which get pretty big after a while). The current property being implemented is SafeIteration: the collection must not be modified while an interator is still calling next.

It is now possible to collect traces from DaCapo: the trace is based on the Callback class starting and ending points.

LTL formulas are converted to Buchi automata. Is it useful to actually compare prefixes of the word?

For empirical language inclusion: could go very fast! The two automata have to be updated at the same time, one's changes to be tried in the other.


Emptiness could get very fast as well by introducing forgetfulness...

06/05/14
Naive specification translator is now working, it has now to be tested. Tomorrow:
- test with SafeIteration property and hope that it works
- test with HasNext property and hope that it works

For this some extra trace translations will have to be implemented.

06/07/14
There seems to be a lot of translation work going on, so the decision has been taken to implement a translation language interpreter (TRF, Translation Rules File). With this language the aim is to:
- detect subclasses from classes (quickly)
- retrieve IDs where necessary
- interpret certain interesting return values
- give codes to all useful methods

On the implementation level:
- static methods will always be ignored

TRF language shape:
TEXT <- LINE*
LINE <- “--” comments <ENDLINE>
LINE <- “subclass:”<class_name> <method_name>:<number> <RETURN_RULE>+ <ENDLINE>
LINE <- “equals:”<contain_string> <method_name>:<number> 
									<RETURN_RULE>+ <ENDLINE>
RETURN_RULE <- <number>
RETURN_RULE <- “object:”(“ID” | <number>)
RETURN_RULE <- “equals:”<contain_string>“:”<number>

No spaces unless specified.

Since there is no ambiguity this will be implemented as usual, with feeling.

06/08/14
This all works now.
Next optimisation to be tested: disable copy of “fixed” registers.

06/10/14
Optimisation about fixed registers worked a little time-wise, but is probably much more efficient memory-wise.
Now trying to revert fixed registers to map from symbol to register index.
This seems to work remarkably well (10s win on a hundred!)

There is now a need for comparison. Things that need to be done:
- solve the finalize problem
- Try to run RVMonitor on a trace for COMPARISON!
- try more alternative stuff for membership detection

We will start with the second problem.

It seems that this method will always be slower... Indeed, for each event we need 10,000 updates in this instance!

06/12/14
The finalization problem doesn't make any sense given the lack of performance of this method.

Third problem: Bloom filters improve memory usage for set checking. Do we need to test membership in a set? We do, at the moment where a symbol needs to be checked against the symbols in registers. But bloom filters cannot be stripped from elements. Will try with regular hashmaps but unsure this will improve performance (there is a tradeoff between keeping the hashmap updated and copying it, and better reading performance. It is likely this will actually make things worse). In each case this optimisation would be much too low-level, we need something more radically effective.

Meeting w/ Radu:
1. Main idea: update the frontier only where necessary. This will lead to a comparable performance vis-à-vis the RVMonitor thing
2. Make a pre-study of the automaton to determine if at some point registers are read-only, and then think of a system to shift registers from read-only to read-write and vice-versa.
3. If read-only values are 1-5, why not translate them 0-4 and then not bother about symbols at all? i.e. symbol = register number.
4. Bloom filters could be used to test “newness” of a symbol quickly regarding a set of registers. To be explored...
5. Also hashmap<Int,Int> allows perfect reg-symbol and symbol-reg mapping

06/13/14
In order of proceedings:
1. Idea worked much less well than expected, but it is saveable. 
The observation is that a symbol leaving a ocnfiguration totally unchanged never happens, because usually at least the registers are changed. Since we're only interested in detecting physical state change, we have to find a way to ignore register-change-only symbols.
For this two categories of configurations appear: stable ones, ones that are in a state where it is easy to stay and compulsory to survive; and unstable ones, ones that may infer death and that will easily send you to another state.
Unstable ones always have to be expanded since only them can infer death. Stable states should only be expanded if they receive a symbol they require (symbolNeeders) or if a strictly outgoing transition has rho as its label, and receives a fresh symbol (rhoCompatibles).

It will proceed in several steps:
- Preprocess the automaton to find which states are stable, and which are unstable.
- Preprocess the automaton to sort transitions between strictly outgoing and self-transitions.
- Preprocess the automaton to know, per physical state, which register symbols have to be declared for quick updates.
- Modify the automaton to destroy the whole ternary side, making sure this does not create problems.
- Modify the search algorithm:
	- Pop new symbol.
	- Expand unstable configs (configs with unstable states). This will clean out all the mortal ones, and expand unstable ones which will need to be expanded whatever happens.
	- Expand configs which declare needing the symbol for a strictly outgoing transition. This information depends on the configuration. Update the rho register with previous value on expand. (????)
	- Expand configs that have strictly outgoing transitions which are enabled by adding the current symbol with a rho value. This information depends on the physical automaton state.
	- Update the information necessary to the previous steps. Make sure to update only stuff that is strictly config-dependent (as opposed to state-dependent). Only ask from configurations that were recently updated, which are now stable, and which also remember what they said previously.

06/15/14
- Stable states need to exist in form of a list rather than an in-state attribute: they are to be processed linearly.

(Optimisation to be made: remember hashcodes when nothing changes).
(The test infrastructure will have to be cleaned up at some point: the new algorithm does not require the automaton to be a register automaton).

The frontier will now be made up of a set, which stores search states that are NOT on the same word distance.

06/18/14
First idea speeds up membership checking 500 times. Success.
(Might be useful to make deeper analysis of stability in automata: some of the first states encountered in the automaton might not have all states assigned and are therefore stable. To be explored with the “automaton recognising words with a repetition in them”).
Will try another speedup: idea no 3.

06/19/14
Idea no. 4 is no good: the alphabet's size is small (or at least limited) compared to the potential word size. Extra bloom filtering will add 

Replaced sets by lists in the greedy paradigm, this speeds up the process again (1.1s for 3M symbols). Why is this? No more hash codes computed.

Idea no. 3 was a good idea and speeds up the process again, 3M symbols -> 1.07s.

06/23/14
Collecting another large trace with the tracer program, and with the new formalism 0<=s<N. This is to perfect idea no. 3 even more. New ideas:
* Preprocess the automaton to eliminate unnecessary writes.
* Sets might have overhead for “need symbols”.

Today's meeting – no particular order:
1. Get traces from dacapo
2. Improve speed of tracer
3. No more low-level optimisations until traces take more than 10s
4. Start thinking about writing up membership
5. More profiling to see what takes time
6. Think about what constitutes frontier/death/.. sizes: explain the numbers.
7. Deadline for membership: July 1st.
8. Get a grip on 5 properties, and 5 nice traces from Dacapo for each of those.
9. Take a look at the tainted property: this should not be possible to examine with JavaMOP: there is an unbounded number of objects that javamop cannot handle, and it should be possible to handle these through nondeterminism.
10. Try to outline garbage collection and finalization.
11. Have a look at memory consumption for the reference and the search algorithm.
12. Unify the properties tested by both the reference and the search algorithm.

Some possible optimisations:
1. Be more aggressive on the “outgoing” side of transitions vis-à-vis states: “expand” should only add new physical states.
This enforces the following rule: only configurations with different states should be added.

06/24/14
Investigation: the greedy method also makes the automaton skip some symbols, since sometimes nobody is asking for the default one for example. Which is why less nodes are expanded than the number of symbols in the input word.

With 20M symbols analysing a trace takes 7s.

Planning for the next days:
Monday:
- Improve speed of tracer (done, x4)

Tuesday (today):
- Think about what constitutes collected sizes: explain the numbers (done)
- Implement that one last optimisation (see above) (done)
- More profiling to see what takes time (time and memory monitoring!)
- Test garbage collection/finalisation (override finalize)

Wednesday:
- Think about the tainted property.
this should not be possible to examine with JavaMOP: there is an unbounded number of objects that javamop cannot handle, and it should be possible to handle these through nondeterminism.
- Program 5 properties to test from the paper about garbage collection.

Thursday:
- Get 5 traces from dacapo: might have to improve tracer speed
- In the meantime build 5 javaMOP references WITH THE EXACT SAME PROPERTY
- Think some more about the tainted property thing

Friday:
- Make sure every banchmark works
- Make some measurements through profiling about time and memory expenditure
Might have to modify the test infrastructure for this (wait after translation load).

Saturday:
- Read report writing guidelines and examples
- Write plan for whole project report
- Write plan for membership
(profiling, optimisations, theory, )
- Make initial canvas for LaTeX report.

Sunday:
- Organise how optimisations will be presented
- Write up nice descriptions of how optimisations work.

Monday: 
- Meeting with Radu

Tasklist today
---------------
That last implementation of the optimisation was terrible, it gave a 5% decrease in performance. This is probably because deleting things from the frontier is much much less aggressive – outbalancing the optimisation itself.

06/25/14 (Wednesday)
The tainted property is very interesting! Possible to show javaMOP can't analyse it the way we do? Maybe reduce a problem to it, a problem that LTL can't express?

Tainted property implemented. It seems that JavaMOP would be able to implement this property, so maybe it is worth investigating.

06/26/14 (Thursday)
Radu just sent examples of properties – analysing and implementing, since these are very closely linked to behaviours in DaCapo.

Starting with the servlet property: not outputstream and writer at the same time!
https://github.com/rgrig/topl/blob/master/examples/dacapo/tomcat.topl#L35

06/27/14 (Friday)
Major improvement to the Tracer and running script, benchmarks are ready to be collected.

06/29/14 (Sunday)
Catching up on Today & Yesterday.

* What the report guidelines say:

The main body of the dissertation should be preceded by a table of contents listing chapters and sections. Every page in the main body should carry a header
indicating the current chapter or section.

The main body of the text of a typical dissertation will contain:
 - an introduction: the first chapter should introduce the subject of the
dissertation and explain the structure of the text to the reader.
 - an explanation of the problem: a second chapter should explain the problem
to be studied, or the context in which the work takes place.
 - a description of the method: a third chapter should introduce the method used
to solve the problem, or the formal techniques employed.
 - an account of the work: the following chapters should present the work
carried out during the project, including any practical results and theoretical
insights obtained.
 - conclusions: the final chapter should contain conclusions drawn from the
project, comparisons which may be made between this and existing work or
practice, and suggestions regarding the extension or continuation of the work.
 - a bibliography, and/or list of references


Material that is used to support the work but does not have a place within the body
of the text may be included as an appendix. Typical examples include program
code, mathematical proofs, and sample output.

The dissertation should be securely bound in such a manner as will facilitate reading
and assessment. Students may wish to submit additional material in electronic form;
this will not affect the formal assessment of the dissertation, but may prove useful to
the examiners. See also section 4.11.2.


* How this project will be organised:

[INTRODUCTION]
- Introduction to register automata
  * How they informally work 
  * Why we need them 
  * What can they do more as a consequence?
- Application areas: scarce
  * NOT runtime verification
  * Find some examples in the French guy's paper
- The plan of this project
  * There is a problem that has not been solved (explain quickly)
  * Take a look at alternative applications such as Runtime Verification and Software Verification (finding a path or testing a specification).
  * Also do not assume to find the solution as the problem is supposed to be intractable.
  * The problem is the theoretical performance of algorithms. Now we want to know the practice.
  * Glimpse of the result: it has been found that these problems are not intractable.
- Plan of this dissertation
  * Formal presentation of the problem
  * Description of the method
  * Presentation of ideas and results

[CONTEXT]
- Notations
  * Formal definition of a register automaton.
  * Formal definition of a word and a language.
- Some consequences of the infinite alphabet and registers
  * This is not a finite-state automaton.

[THE PROBLEM]
 
- What problems around register automata are interesting:
  * Membership
  * Emptiness
  * Inclusion
- The problem itself:
  * The assumption of an infinite alphabet makes the problem much harder compared to a finite automaton. Examples of things that don't work anymore.
  * Theorems about how the problems are hard and intractable.
  * But there is no practical research.
- The problem's question.

[THE METHOD]
- The general method
  * Given a problem, iterations over the following algorithm:
	. Think
	. Implement an algorithm/improve the current version
	. Test for validity
	. Test for performance
	. Conclude on progress
	. Profile for hot spots
  * General advice found in the experimental programming paper: summarise
- How this applies here
  * Choice of instruments
	. My computer
	. Java: fast coding but sometimes unreliable
	. Need for an optimisation measure 
  * The test infrastructure
  * The quest for examples
	. First some “theoretical examples”
	. Then some real-world ones: runtime verification
	. Choose a time limit for testing (about 60s?)
  * A versioning system to keep track of everything that happened.
- The base version of an automaton when encoded

[RESULTS: MEMBERSHIP]
FIRST SUBSECTION: The problem for membership (introduction)
- Some more theory about membership
  * The deterministic case which is trivial
  * The problem nondeterminism induces
  * Why this can't be solved the way we would do it with finite-state automata.

SECOND SUBSECTION: Finding samples to test membership on
- We will try some theoretical examples at first
- Randomly generated examples don't make much sense
- Why runtime verification is a good idea
  * Real-world examples.
  * Might be useful in runtime verification (more general)
- The properties we will test

- The traces we collected: 20M events normally
  * Theoretical ones
  * Dacapo

- This covers more than the current tools in runtime verification

THIRD SUBSECTION: The actual results


- Naive solutions
  * A link with Intelligent Systems: this is a search problem.
  * A presentation of the baseline algorithms that were implemented and quickly abandoned:
	. LDFTS
	. BFGS
  * An improvement to BFGS: BFLGS
  * A comparison of LDFTS and BFLGS
	. BFLGS is usually better than LDFTS: we know how many steps, smaller frontier, smaller tree.
	. but LDFTS can be asymptotically better than BFLGS in some twisted cases.
  * This is a problem of “number of nodes expanded”: it is possible to improve the performance of node expansion (and examples will follow) but in the end what is important is the number of nodes that are expanded – and this rapidly grows to billions for a million-length word.
- No need to remember paths! The example of forgetful BFLGS
- Outlook on the real world: a possible application field is runtime verification.
  * Trace collection 
  * Property translation into automata 
  * Comparison with references
  * Observation: a lot of updates are useless!
- Dominance of Greedy-MBS
  * The idea
  * The results
  * Profiling results

- A try at heuristics
  * The idea
  * Why it didn't work out well:
	. Memory 
	. Preprocessing
	. The disastrous case of non-membership

[RESULTS: EMPTINESS]

[RESULTS: INCLUSION]

[CONCLUSION]
- The problems are not intractable

- Newly acquired skills with this project
  * How to make a tracer in Java
  * Some catches in Java (pooling, etc.)


* While this is all very interesting some research is left for membership:
  - profiling on the latest algorihtm


06/30/14
* Property to automaton translation
* Tomcat with forms manipulation: install then look at examples

07/01/14
Priority task: write up optimisations for membership, so other problems can be addressed later without any back thoughts.
- Write LaTeX canvas
- Start editing
- Collect numbers where necessary

- The figures that are necessary
 * The deterministic membership check of a small automaton [OK]
 * 

07/05/14
WHERE ARE WE NOW?

We have the deterministic check of the “abacb” automaton: 50M symbols in 2 sec.

For nondeterminism:
Traces collected (8):
- Has_next on avrora, 15M symbols
- Has_next on custom, 20M symbols
- Has_next on tomcat, 8M symbols
- Safe_iter on custom, 100k symbols
- Safe_iter on tomcat, 13M symbols
- Tainted Sink Source on custom, 20M symbols
- Unique servlet output on tomcat, 1M symbols
- Unsafe map iter on tomcat, 3.5M symbols
- Unsafe map iter on pmd, 7.8M symbols
- Unsafe map iter on xalan, 2.3M symbols

07/06/14
Results collection plan:

Has_next.avrora as a basis for all small algorithms: LDFTS, BFGS, BFLGS, F-BFLGS
Then has_next.avrora, safe_iter.tomcat, tss.tss_custom, uso.tomcat, umi.pmd on G-BFLGS

-Better multitype support
-Better exception handling: is class not found important?

07/12/14

