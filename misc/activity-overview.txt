04/30/14
First basic implementation of an automaton. Question: which alphabet? We will here consider the integers. NO UPPER BOUND hypothesis must be made!
Mu and Rho are (hash)maps.
There seems to be a link with CNF and SAT solving problem; take a look later.
For now, the transition set is seen as sparse: a matrix representation is therefore useless. We also maximise reading access times: the transition system is seen as a hashset (key: state) of a hashset (key: label) of a list of states.
Each automaton object is seen as an automaton model; the object is immutable during any computation.
First write deterministic algorithm.
New question: how does one perform a quick check of whether there is a register that contains the current symbol? For now, we'll do it naïvely: check all the registers. Later on, an optimisation is to keep a record of the current registers' content in form of a (hash)set.
This algorithm is/could be linear with the number of symbols to test. The number of registers and states does not impact the computation time.

Questions:
“A Turing machine can simulate membership for NFA in NLOG”: how?
Computational complexity of MEMD.
Why use reduction while it's straightforward?

See email dated today: ignore these questions, authors made some unclear assertions.

05/01/14
[coding nondeterministic membership]
Try:
A basic BFS/other search algorithm. An interesting heuristic should be found.
A different vision over the problem:

A RA can be seen as an NFA over a finite word w over a finite alphabet E: w is composed of the register indices where symbols are progressively stored (or not); in the end a word is exactly a string of transition labels, as shown in the representation of a RA.

[reflexion on emptiness]
If there is a word in the language defined by an automaton A, then the following algorithm will return such a word:
BFS/A* search from initial state to final state. Not to be confused with the search STATE.
If the language is empty, this search will not terminate, which makes the algorithm/the method useless.

FMA (Kaminski) has some mistakes, i.e. p 334 tau values do not have to be distinct (“abaaba” passes membership test).

05/02/14
Finished nondeterministic membership problem with a first naïve solution: just LDFTS. A next step would be to find a nice heuristic.

Could it be possible to divide an automaton into two subsets, deterministic states and nondeterministic ones, and then see the problem as a “chance” game? Or a game with contingency plans? MINIMAX?

05/03/14
Empirical emptiness problem: PROPOSITION: it is only necessary to test the automaton with the following subset of the alphabet:
{elements in the initial registers} U {other distinct elements}
the total set size being the number of registers + 1.

WHY: we always need the possibility of filling up all the registers and having new elements coming in, which is why there need to be at least NR+1 elements in the alphabet subset.
The automaton can only remember seeing NR elements, so if there is always a new element, it will be seen as “new”.

05/04/14
The first version of a naïve empirical emptiness check works. It probably does way too much work: when all words of size N are refused, words of size N+1 are checked, and the work done on size N is forgotten and recomputed (very intensive).
In each case it works perfectly, and for example for Example 3 (automaton recognising words with double repetition, ie two different symbols are repeated): [1,1,0,0] is returned.

Idea: create a “generative” emptiness check, with the previous intuition; the decision algorithm would actually be complete given the previous PROPOSITION: the state space is big but not infinite.
The decision algorithm would be based on a BFGS/A*G algorithm, where the G factor is very important: we are not interested in cycles. We can see the problem as a search problem from an initial state to whatever final state we reach first. A* could use a heuristic based on the physical distance of the state to a final state (to be precomputed).
WARNING: there might be unvoluntary cycles introduced if we go to the same state, with the same registers assigned, but with different values. Since all assigned values are distinct, there might be some symmetry (isomorphism) in this CSP that could be avoided.

05/05/14
Generative emptiness seems to work OK. Some mistakes have been made regarding permutations of register values (see previous WARNING).

-> Meeting with supervisor; TODO:
- Deterministic membership is straightforward, agreed.
- Nondeterministic membership can be optimised by using an adapted version of BFTS: Breadth-First-Local-Graph-Search. LDFTS performs less good in a diamond-chain-shaped automaton's case: BFLGS will be linear in all cases, LDFTS will be exponential as usual. Try to find an example where LDFTS performs better; idea: choose a tree that has a lot of branches with a deep-found solution. This only works better if the word is part of the language.
- Nondeterministic can also be solved by assigning hashmaps to each physical state, where a value (label?) points towards a set of configurations. To be explored and implemented.
- Emptiness decision problem: the equality check should be reviewed as explained above.
- Read the paper about emptiness, the proof is probably very similar to what's going on in the chosen algorithm.
- Also try out a heuristic for emptiness checking (A*). This might speed up cases where the language is nonempty.
- Explore language inclusion
- All the previous algorithms should be tested on useful examples of automata. Random generation can be inspired from random graph generation. Then a good idea is to start with a small sticky manual example, and try to generalise it and automatise its generation. The diamond-chain-shaped automata are a good example of what kind of automaton can be automatically generated.

Example 4 is a basic example where LDFTS is disastrous in case the word is not in the language.

It seems that BFLGS is indeed useful in the case of a diamond-chain-shaped automaton, but how useful is it in average? And compared to LDFTS?
STRATEGY: 
1) Get tests up and running: 
	a. Find interesting automata for testing
	b. Improve the results container to get more interesting results:
		- Number of nodes expanded
		- Frontier size
		- Operations performed
2) Implement different algorithms for nondeterministic membership
3) Compare on large automata

So there we go:
1) Random automata seem OK, but we have to find out how to choose the parameters that go with them. Quick cleanup of RAGenerator's structure.

Finished Diamond-chain-shaped (DCS) automata.

05/06/14
Now improving test infrastructure.

05/08/14
Test infrastructure has been improved a lot. Some work still needs to be done (polymorphism of algorithms and search algorithms for instance).
Diamond-chain-shaped automata seem to give the expected result: DFS is explosive (exponential increase) while SB-BFS is linear. Tests made with listed membership test infrastructure.

Some questions:
- How useful would it be to test all the algorithms?
- Why is the DCS automaton's instance interesting?
- Try to find a nice example where BFLGS loses all its efficiency.

* The point is that DFS can be -asymptotically- worse than SB-BFS (see example 4).

SB-BFS can be worse than DFS but not asymptotically. 
Proof:

We're going to show that SB-BFS has, in the worst case, always the same asymptotic performance as DFS. The case where membership fails is straightforward: DFS and SB-BFS expand all the nodes, and because of pruning, SB-BFS does always better. We're looking for a case where DFS decides faster, and that's only possible if membership succeeds.

Reformulation:
Let A be an automaton, with registers R and state set Q. Let (wn) be an infinite word list such that DFS finds a path in O(f(n)) nodes expanded for wn in A, and |wn| = n (i.e. the path is of length n). We suppose that, on this list, SB-BFS is worse in the number of nodes expanded. Let's show that SB-BFS's performance is in O(f(n)).

Let S be a frontier at some point in SB-BFS's exploration. The search states in this frontier are distinguished by three criteria:
- The sublist of letters in the word left to explore
- The values in the registers
- The name of the current physical state

As it happens:
- A frontier in BFS symbolises a circle in a state space where the distance is the number of nodes in the path to go from one space to the other; in other words, for every search state in S, the sublist of letters to explore is the same.
- Let A be the set of letters in the initial word, and |A| its size. Then there are D = (|A|+1)^|R| possibilities of register assignments.
- There are |Q| possible physical states.
As a consequence, the maximum number of search states in S is D*|Q|.

SB-BFS finds the solution in n frontier swaps. Therefore it must expand in the worst case D*|Q|*n nodes. But:
- DFS has a better performance in this example. Let g(n) be the number of nodes DFS expands in search for the final state. Then g(n) <= D*|Q|*n.
- DFS must at least expand n nodes. Therefore

		n <= g(n) <= D*|Q|*n

and two results are inferred:
- g(m) = O(m) (i.e. a candidate for f is n → n)
- since D*|Q|*m = O(m), SB-BFS has the same asymptotic performance as DFS.

Therefore, in case DFS has a better performance than SB-BFS, even then SB-BFS does not have a worse asymptotic performance.

A case where SB-BFS is worse than DFS: example5.fma. See test21.csv. This example is a fork between example 4 and another useless cyclic automaton. BFS's frontier will always be bigger, and therefore in DFS's optimal case, DFS is faster. Furthermore, there is just a factor 3 difference.

DFS is always worse than SB-BFS when membership fails.


